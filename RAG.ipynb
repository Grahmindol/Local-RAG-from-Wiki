{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet : Construire un RAG basé sur les données Minecraft de Wikipédia\n",
    "\n",
    "Ce projet vise à développer un système de **Retrieval-Augmented Generation (RAG)** qui tire parti des informations disponibles sur le Wikipédia de Minecraft. Le pipeline comprend plusieurs étapes, allant de l'importation des bibliothèques nécessaires jusqu'à la création d'une base de données vectorielle et la mise en place d'un système de requêtes utilisant un modèle de language.\n",
    "\n",
    "---\n",
    "\n",
    "## Étapes du Projet\n",
    "\n",
    "### 1. Importer les bibliothèques nécessaires\n",
    "\n",
    "Pour commencer, nous devrons importer les bibliothèques Python indispensables pour manipuler les données, effectuer les requêtes, construire une base de données vectorielle et interagir avec le modèle de langage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import ollama\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Récupérer les données de Wikipédia sur Minecraft\n",
    "\n",
    "Dans cette étape, nous établirons une connexion avec l'API de Wikipédia pour récupérer les données pertinentes sur Minecraft.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base URL for the API\n",
    "url = \"https://fr.minecraft.wiki/api.php\"\n",
    "\n",
    "# list des categories contenat des info jugé utile.\n",
    "categorys = [\"Bloc\",\"Environnement\",\"Gameplay\",\"Objets\",\"Redstone\",\"Entitée\"]\n",
    "\n",
    "# Function to fetch category members\n",
    "def fetch_category_members(category, limit=500):\n",
    "    members = []\n",
    "    cmcontinue = None\n",
    "\n",
    "    while True:\n",
    "        # API request parameters\n",
    "        params = {\n",
    "            \"action\": \"query\",\n",
    "            \"list\": \"categorymembers\",\n",
    "            \"cmtitle\": f\"Catégorie:{category}\",\n",
    "            \"cmlimit\": limit,\n",
    "            \"format\": \"json\",\n",
    "        }\n",
    "        if cmcontinue:\n",
    "            params[\"cmcontinue\"] = cmcontinue\n",
    "\n",
    "        # Make the API request\n",
    "        headers = {\"User-Agent\": \"MyScript/1.0 (myemail@example.com)\"}\n",
    "        response = requests.get(url, params=params, headers=headers)\n",
    "        data = response.json()\n",
    "\n",
    "        # Collect members\n",
    "        members.extend(data.get(\"query\", {}).get(\"categorymembers\", []))\n",
    "\n",
    "        # Check if more pages are available\n",
    "        cmcontinue = data.get(\"continue\", {}).get(\"cmcontinue\")\n",
    "        if not cmcontinue:\n",
    "            break\n",
    "    return members\n",
    "\n",
    "def fetch_rvid(title, date=\"2021-01-01T00:00:00.000Z\"):\n",
    "    # API request parameters\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "        \"format\": \"json\",\n",
    "        \"prop\": \"revisions\",\n",
    "        \"titles\": title,\n",
    "        \"formatversion\": \"2\",\n",
    "        \"rvprop\": \"ids\",\n",
    "        \"rvlimit\": \"1\",\n",
    "        \"rvstart\": date,\n",
    "        \"rvdir\": \"older\"\n",
    "    }\n",
    "\n",
    "    # Make the API request\n",
    "    headers = {\"User-Agent\": \"MyScript/1.0 (myemail@example.com)\"}\n",
    "    response = requests.get(\"https://fr.minecraft.wiki/api.php\", params=params, headers=headers)\n",
    "\n",
    "    # Check if the response was successful\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract the revisions data safely\n",
    "        pages = data.get(\"query\", {}).get(\"pages\", [])\n",
    "        if pages:\n",
    "            page_info = pages[0]\n",
    "            revisions = page_info.get(\"revisions\", [])\n",
    "            \n",
    "            if revisions:\n",
    "                # Return the revision ID if found\n",
    "                return revisions[0].get(\"revid\", None)\n",
    "    \n",
    "    # Return None if no revisions are found or if there's an issue\n",
    "    return None\n",
    "\n",
    "def extract_table_description(table):\n",
    "\n",
    "    # Extraire les ingrédients\n",
    "    ingredients_cell = table.find('td')\n",
    "    ingredients = ingredients_cell.get_text().replace('+', ', ')\n",
    "    position = ingredients.rfind(\", \")\n",
    "    if position != -1:\n",
    "        ingredients = ingredients[:position] + \" et \" + ingredients[position + 1:]\n",
    "    \n",
    "    \n",
    "    # Extraire le produit final en filtrant le texte\n",
    "    output_image = table.find('span', class_='mcui-output').find('img')\n",
    "    alt_text = output_image.get('alt')\n",
    "    \n",
    "    # Si \"alt\" contient des détails inutiles comme \"Invicon Target.png\", nettoyer le texte\n",
    "    output_name = alt_text.split(\":\")[-1].strip()  # Extraire après les deux-points\n",
    "    \n",
    "    # Générer une description textuelle propre\n",
    "    description = f\"Pour fabriquer une {output_name}, utilisez les ingrédients suivants : {ingredients}.\"\n",
    "    return description\n",
    "\n",
    "def fetch_page_content(title, date=\"2021-01-01T00:00:00.000Z\"):\n",
    "    rvid = fetch_rvid(title,date)\n",
    "    if not rvid:\n",
    "        return None\n",
    "    page_url = f\"https://fr.minecraft.wiki/w/{title.replace(' ', '_')}?oldid={rvid}\"\n",
    "\n",
    "    print(f\"collecting data from : {page_url}\")\n",
    "    \n",
    "    headers = {\"User-Agent\": \"MyScript/1.0 (myemail@example.com)\"}\n",
    "    response = requests.get(page_url, headers=headers)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: Unable to fetch the page. Status code {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    soup.prettify(formatter=\"html5\")\n",
    "    \n",
    "    paragraphs = soup.select('#mw-content-text > div.mw-parser-output > p')\n",
    "    paragraph_texts = [p.get_text() for p in paragraphs if p.get_text() if not p.get_text().strip().endswith(\":\")]\n",
    "\n",
    "    fabrications = soup.select('#mw-content-text table[data-description=\"Fabrication\"]')\n",
    "    paragraph_texts += [extract_table_description(f) for f in fabrications]\n",
    "    \n",
    "    return paragraph_texts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extraire et traiter les données récupérées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtenir la liste des page \n",
    "categorys_page = {str : fetch_category_members(str) for str in categorys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, paragraph in enumerate(fetch_page_content(\"Fabrication\"), start=1):\n",
    "        print(f\"Paragraph {i}:\\n{paragraph}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Construire une base de données vectorielle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_wiki():\n",
    "    chunks = []\n",
    "    for page in categorys_page:\n",
    "        print(f\"loading page : {page}\")\n",
    "        chunks += fetch_page_content(page)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "chunks = split_wiki()\n",
    "print(f\"Total number of chunks: {len(chunks)}\")\n",
    "print(\"\\n\")\n",
    "embeddings = OllamaEmbeddings(model=\"embedding-model-here\") #Replace model with your preferred embedding model\n",
    "\n",
    "db = Chroma.from_documents(chunks, embeddings, collection_name = \"local-rag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Mettre en place le système de requêtes au modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Initialize the client\n",
    "client = ollama.Client()\n",
    "\n",
    "# Define the model and prompt\n",
    "model_name = \"qwen2.5:0.5b\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scraped_text = fetch_page_content(categorys_page[\"Bloc\"][1][\"title\"])\n",
    "\n",
    "# Prompt for cleaning text\n",
    "prompt = f\"\"\"\n",
    "Clean and structure the following text to make it readable and coherent. \n",
    "Ensure that the output stays true to the original content, without introducing new information, changing the original meaning, or adding extraneous details. \n",
    "Only adjust grammar, punctuation, and structure for clarity. \n",
    "Do not add or modify any content. \n",
    "Keep technical terms intact. \n",
    "Here is the text:\n",
    "\n",
    "{scraped_text}\n",
    "\"\"\"\n",
    "\n",
    "# Generate response\n",
    "response = client.generate(model=model_name, prompt=prompt, options={\"temperature\":0.1})\n",
    "\n",
    "# Print the cleaned text\n",
    "print(\"Cleaned Text:\")\n",
    "print(response[\"response\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
